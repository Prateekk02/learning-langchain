{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f2933f2",
   "metadata": {},
   "source": [
    "# Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ed7fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "194d7ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prateek Kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1686: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "from pydantic import Field, BaseModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route the user to the most relevant datasource.\"\"\"\n",
    "    \n",
    "    datasource : Literal[\"python_docs\", \"js_docs\", \"golang_docs\"] = Field(..., description=\"Given the user question choose which of the datasource will be the most relevant.\")\n",
    "    \n",
    "# LLM\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# LLM with structured output parser\n",
    "structured_llm = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"\n",
    "You are an expert in routing user's question to appropriate datasource.\n",
    "Based on the programming language the question is referring to, route it to relevant datasource.  \n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "   [\n",
    "       (\"system\", system),\n",
    "       (\"human\", \"{question}\")\n",
    "   ]\n",
    ")\n",
    "\n",
    "# Router Chain\n",
    "router = prompt | structured_llm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "871d1b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "question= \"\"\"\n",
    "Why this code is not working?\n",
    "\n",
    "from langchina_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "parser = StrOutputParser()\n",
    "\n",
    "template = '''You are an helpful assistant answer the question: '''\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template\n",
    ")\n",
    "\n",
    "chain =  prompt | llm | parser\n",
    "\"\"\"\n",
    "\n",
    "result = router.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dca7ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up route logic\n",
    "\n",
    "def choose_route(result):\n",
    "    if \"python_docs\" in result.datasource.lower():\n",
    "        return \"chain for python_docs\"\n",
    "    elif \"js_docs\" in result.datasource.lower():\n",
    "        return \"chain on js_docs\"\n",
    "    elif \"golang_docs\" in result.datasource.lower():\n",
    "        return \"chain on golang_docs\"\n",
    "    \n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "final_chain = router | RunnableLambda(choose_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "782c66c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = final_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df2a3769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chain for python_docs\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b134c60b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
